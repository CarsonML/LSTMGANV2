{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from music21 import *\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "from random import shuffle\n",
    "import zipfile\n",
    "import gensim\n",
    "import random\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(music,num_neurons, num_dense_neurons):\n",
    "    bidir = tf.keras.layers.Bidirectional(tf.keras.layers.CuDNNLSTM(num_neurons), input_shape=(3072, 50))\n",
    "    hidden_dense = tf.keras.layers.Dense(num_dense_neurons, activation = tf.nn.relu)\n",
    "    condense = tf.keras.layers.Dense(1)\n",
    "    sigmoid = tf.keras.layers.Activation('sigmoid')\n",
    "    \n",
    "    layer1 = bidir(music)\n",
    "    layer2 = hidden_dense(layer1)\n",
    "    layer3 = condense(layer2)\n",
    "    final_output = sigmoid(layer3)\n",
    "    return tf.keras.Model(music, final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(original_input_music, input_music):\n",
    "        \n",
    "        hidden_output = tf.keras.layers.CuDNNLSTM(200, activity_regularizer = tf.math.sigmoid)(input_music)\n",
    "        \n",
    "        repeated_output = tf.keras.layers.RepeatVector(1536)(hidden_output)\n",
    "        \n",
    "        #end_sequence = tf.compat.v1.keras.layers.CuDNNLSTM(50, return_sequences = True, activity_regularizer = tf.math.sigmoid)(repeated_output)\n",
    "        \n",
    "        end_sequence = tf.keras.layers.LSTM(50, return_sequences = True, activation = tf.math.sigmoid)(repeated_output)\n",
    "        results = tf.keras.layers.Concatenate(1)([input_music, end_sequence])\n",
    "        return tf.keras.Model(original_input_music, results), results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(lis, length):\n",
    "    counter = 0\n",
    "    string = \"\"\n",
    "    for item in lis:\n",
    "        string = str(item)\n",
    "        zipfilePath = (\"./clean_data/\" + string + \".zip\")\n",
    "        zip = zipfile.ZipFile(zipfilePath)\n",
    "        zip.extractall(\"./clean_data\")\n",
    "        pickle_file = open(\"./clean_data/clean_data/\" + string + \".pickle\",\"rb\")\n",
    "        lis = pickle.load(pickle_file)\n",
    "        pickle_file.close()\n",
    "        ray = np.array(lis)\n",
    "        \n",
    "        ray = np.transpose(ray)\n",
    "        index = random.randint(0,ray.shape[0]-1-length)\n",
    "        ray = ray[index:index+length, :]\n",
    "        if counter == 0:\n",
    "            final = np.reshape(ray, [1,length,88])\n",
    "        else:\n",
    "            final = np.concatenate((final, np.reshape(ray, [1,length,88])), 0)\n",
    "        shutil.rmtree(\"./clean_data/clean_data\")\n",
    "        counter = counter + 1\n",
    "    return (final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "plt.figure(figsize = (15,10))\n",
    "fig = plt.gcf()\n",
    "fig.show()\n",
    "fig.canvas.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    music = tf.keras.Input([3072,88])\n",
    "    input_music = tf.keras.Input([1536,88])\n",
    "\n",
    "    coded_input_music = tf.keras.Input([3072,50])\n",
    "\n",
    "    test_discrim_input = tf.keras.Input([3072,50])\n",
    "\n",
    "    encode = tf.keras.layers.Dense(50, activation = \"relu\")\n",
    "    decode = tf.keras.layers.Dense(88, activation = 'sigmoid')\n",
    "\n",
    "    encoded_dis_music = tf.keras.layers.TimeDistributed(encode)(music)\n",
    "    encoded_gen_music_input = tf.keras.layers.TimeDistributed(encode)(input_music)\n",
    "\n",
    "    decoded_music = tf.keras.layers.TimeDistributed(decode)(encoded_dis_music)\n",
    "    decoded_input_music_for_model = tf.keras.layers.TimeDistributed(decode)(coded_input_music)\n",
    "\n",
    "    decoder_model = tf.keras.Model(coded_input_music, decoded_input_music_for_model)\n",
    "\n",
    "    decoded_input_music = tf.keras.layers.TimeDistributed(decode)(encoded_gen_music_input)\n",
    "\n",
    "    encoder_decoder = tf.keras.Model(inputs = [music, input_music], outputs = [decoded_music, decoded_input_music])\n",
    "\n",
    "    encoder_decoder.compile(optimizer = 'adam' , loss='categorical_crossentropy', loss_weights = [.5,.5])\n",
    "\n",
    "    encode.trainable = False\n",
    "    decode.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    discriminator = build_discriminator(test_discrim_input, 128, 50)\n",
    "\n",
    "    real_discriminator_output = discriminator(encoded_dis_music)\n",
    "\n",
    "    real_discriminator = tf.keras.Model(music, real_discriminator_output)\n",
    "\n",
    "    discriminator.compile(optimizer = 'adam', loss='binary_crossentropy')\n",
    "    real_discriminator.compile(optimizer = 'adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    generator, to_dis = build_generator(input_music, encoded_gen_music_input)\n",
    "    discriminator.trainable = False\n",
    "    real_discriminator.trainable = False\n",
    "    fake_lables = discriminator(to_dis)\n",
    "    combined = tf.keras.Model(input_music, fake_lables)\n",
    "    combined.compile(optimizer = 'adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total_data = 15509\n",
    "batch_size = 500\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1ecf48bca1aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m }\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_total_data\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdis_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_total_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    }
   ],
   "source": [
    "loss_dict= {\n",
    "    'e_loss':[],\n",
    "    'g_loss':[],\n",
    "    'd_loss':[]\n",
    "    \n",
    "}\n",
    "for e in range(epochs):\n",
    "    num_batches = num_total_data // batch_size\n",
    "    dis_list = list(range(num_total_data))\n",
    "    gen_list = list(range(num_total_data))\n",
    "    random.shuffle(dis_list)\n",
    "    random.shuffle(gen_list)\n",
    "    for i in range(num_batches):\n",
    "        print(\"getting data\")\n",
    "        start_data_gen = next_batch(gen_list[i*batch_size:i*batch_size + batch_size], 1536)\n",
    "        sequences_dis = next_batch(dis_list[i*batch_size:i*batch_size + batch_size], 3072)\n",
    "        print(\"got data\")\n",
    "        encoder_loss = encoder_decoder.train_on_batch([sequences_dis,start_data_gen], [sequences_dis, start_data_gen])\n",
    "        total_fake_data = generator.predict(start_data_gen)\n",
    "        d_loss_fake = discriminator.train_on_batch(total_fake_data, tf.zeros(batch_size))\n",
    "        d_loss_real = real_discriminator.train_on_batch(sequences_dis, tf.ones(batch_size)*.9)\n",
    "        print(real_discriminator.predict(sequences_dis))\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        g_loss = combined.train_on_batch(start_data_gen, tf.ones(batch_size))\n",
    "        g_test = decoder_model.predict(generator.predict(start_data_gen))\n",
    "        print(g_test)\n",
    "        print(\"batch {} completed! encoder loss: {} discriminator loss: {} generator_loss: {}\".format(i, encoder_loss[0],d_loss,g_loss))\n",
    "        loss_dict['e_loss'].append(encoder_loss[0])\n",
    "        loss_dict['g_loss'].append(g_loss)\n",
    "        loss_dict['d_loss'].append(d_loss)\n",
    "        plt.clf()\n",
    "        plt.subplot(3,1,1)\n",
    "        plt.plot(loss_dict['e_loss']) # plot something\n",
    "        plt.ylabel(\"e_loss\")\n",
    "        plt.subplot(3,1,2)\n",
    "        plt.plot(loss_dict['g_loss'])\n",
    "        plt.ylabel(\"g_loss\")\n",
    "        plt.subplot(3,1,3)\n",
    "        plt.plot(loss_dict['d_loss'])\n",
    "        plt.ylabel(\"d_loss\")\n",
    "        plt.pause(0.01)\n",
    "        fig.canvas.draw()\n",
    "        if i % 10 == 0:\n",
    "            print(\"10 batches completed\")\n",
    "            single_start_data = next_batch([random.randint(0,num_total_data)], 1536)\n",
    "            sample_new_data = decoder_model.predict(generator.predict(single_start_data))\n",
    "            with open(\"./music_samples/{}.pickle\".format(i), \"wb+\") as file:\n",
    "                pickle.dump(sample_new_data, file)\n",
    "        encoder_decoder.save(\"./models/encoder_decoder{}&{}.h5\".format(e,i))\n",
    "        discriminator.save(\"./models/discriminator{}&{}.h5\".format(e,i))\n",
    "        real_discriminator.save(\"./models/discriminator{}&{}.h5\".format(e,i))\n",
    "        generator.save(\"./models/generator{}&{}.h5\".format(e,i))\n",
    "        combined.save(\"./models/combined{}&{}.h5\".format(e,i))\n",
    "                              \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
