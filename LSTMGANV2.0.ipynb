{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from music21 import *\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "from random import shuffle\n",
    "import zipfile\n",
    "import gensim\n",
    "import random\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "#may not need metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(music,num_neurons, num_dense_neurons):\n",
    "    #Note: LSTM not gpu optimized\n",
    "    bidir = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(num_neurons), input_shape=(3072, 50))\n",
    "    hidden_dense = tf.keras.layers.Dense(num_dense_neurons, activation = tf.nn.relu)\n",
    "    condense = tf.keras.layers.Dense(1)\n",
    "    sigmoid = tf.keras.layers.Activation('sigmoid')\n",
    "    \n",
    "    layer1 = bidir(music)\n",
    "    layer2 = hidden_dense(layer1)\n",
    "    layer3 = condense(layer2)\n",
    "    final_output = sigmoid(layer3)\n",
    "    return tf.keras.Model(music, final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(original_input_music, input_music, num_neurons):\n",
    "        hidden_output = tf.keras.layers.LSTM(200, activation = tf.math.sigmoid, input_shape=(1536,50))(input_music)\n",
    "        repeated_output = tf.keras.layers.RepeatVector(1536)(hidden_output)\n",
    "        end_sequence = tf.keras.layers.LSTM(50, return_sequences = True, activation = tf.math.sigmoid)(repeated_output)\n",
    "        results = tf.keras.layers.Concatenate(1)([input_music, end_sequence])\n",
    "        return tf.keras.Model(original_input_music, results), results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(lis, length):\n",
    "    counter = 0\n",
    "    string = \"\"\n",
    "    for item in lis:\n",
    "        string = str(item)\n",
    "        zipfilePath = (\"./clean_data/\" + string + \".zip\")\n",
    "        zip = zipfile.ZipFile(zipfilePath)\n",
    "        zip.extractall(\"./clean_data\")\n",
    "        pickle_file = open(\"./clean_data/clean_data/\" + string + \".pickle\",\"rb\")\n",
    "        lis = pickle.load(pickle_file)\n",
    "        pickle_file.close()\n",
    "        ray = np.array(lis)\n",
    "        \n",
    "        ray = np.transpose(ray)\n",
    "        index = random.randint(0,ray.shape[0]-1-length)\n",
    "        ray = ray[index:index+length, :]\n",
    "        if counter == 0:\n",
    "            #print(\"made final\")\n",
    "            final = np.reshape(ray, [1,length,88])\n",
    "        else:\n",
    "            #print(\"catted\")\n",
    "            final = np.concatenate((final, np.reshape(ray, [1,length,88])), 0)\n",
    "            #print(final.shape)\n",
    "        #os.remove(\"./clean_data/\" + string + \".pickle\")\n",
    "        shutil.rmtree(\"./clean_data/clean_data\")\n",
    "        counter = counter + 1\n",
    "    return (final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "music = tf.keras.Input([3072,88])\n",
    "input_music = tf.keras.Input([1536,88])\n",
    "\n",
    "coded_input_music = tf.keras.Input([3072,50])\n",
    "\n",
    "test_discrim_input = tf.keras.Input([3072,50])\n",
    "\n",
    "encode = tf.keras.layers.Dense(50, activation = \"relu\")\n",
    "decode = tf.keras.layers.Dense(88, activation = 'sigmoid')\n",
    "\n",
    "encoded_dis_music = tf.keras.layers.TimeDistributed(encode)(music)\n",
    "encoded_gen_music_input = tf.keras.layers.TimeDistributed(encode)(input_music)\n",
    "\n",
    "decoded_music = tf.keras.layers.TimeDistributed(decode)(encoded_dis_music)\n",
    "decoded_input_music = tf.keras.layers.TimeDistributed(decode)(coded_input_music)\n",
    "\n",
    "decoder_model = tf.keras.Model(coded_input_music, decoded_input_music)\n",
    "\n",
    "test_decoded_model = tf.keras.Model(music, encoded_dis_music)\n",
    "\n",
    "decoded_input_music = tf.keras.layers.TimeDistributed(decode)(encoded_gen_music_input)\n",
    "\n",
    "encoder_decoder = tf.keras.Model(inputs = [music, input_music], outputs = [decoded_music, decoded_input_music])\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(learning_rate = .01)\n",
    "encoder_decoder.compile(optimizer = 'adam' , loss='categorical_crossentropy', loss_weights = [.5,.5])\n",
    "\n",
    "encode.trainable = False\n",
    "decode.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "discriminator = build_discriminator(test_discrim_input, 128, 50)\n",
    "\n",
    "real_discriminator_output = discriminator(encoded_dis_music)\n",
    "\n",
    "real_discriminator = tf.keras.Model(music, real_discriminator_output)\n",
    "\n",
    "discriminator.compile(optimizer = 'adam', loss='binary_crossentropy')\n",
    "real_discriminator.compile(optimizer = 'adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator, to_dis = build_generator(input_music, encoded_gen_music_input,128)\n",
    "discriminator.trainable = False\n",
    "real_discriminator.trainable = False\n",
    "fake_lables = discriminator(to_dis)\n",
    "combined = tf.keras.Model(input_music, fake_lables)\n",
    "combined.compile(optimizer = 'adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total_data = 15509\n",
    "batch_size = 100\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 14:39:19.309401 4321366912 training.py:2197] Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1536, 88)\n",
      "got data\n",
      "step 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 14:39:30.428936 4321366912 training.py:2197] Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "W0816 14:39:51.725167 4321366912 training.py:2197] Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4877426 ]\n",
      " [0.48261848]\n",
      " [0.49350822]\n",
      " [0.49586377]\n",
      " [0.509082  ]\n",
      " [0.49852195]\n",
      " [0.4973284 ]\n",
      " [0.4812055 ]\n",
      " [0.48764992]\n",
      " [0.49448323]\n",
      " [0.50399435]\n",
      " [0.48919496]\n",
      " [0.49481732]\n",
      " [0.49160644]\n",
      " [0.4949011 ]\n",
      " [0.49997577]\n",
      " [0.4856197 ]\n",
      " [0.49899596]\n",
      " [0.49198276]\n",
      " [0.4941563 ]\n",
      " [0.4940291 ]\n",
      " [0.49354017]\n",
      " [0.50033164]\n",
      " [0.49112967]\n",
      " [0.49514493]\n",
      " [0.49254295]\n",
      " [0.5075601 ]\n",
      " [0.49006552]\n",
      " [0.49428582]\n",
      " [0.49747884]\n",
      " [0.50362873]\n",
      " [0.47807267]\n",
      " [0.48466054]\n",
      " [0.48814598]\n",
      " [0.5054621 ]\n",
      " [0.4933034 ]\n",
      " [0.4940388 ]\n",
      " [0.4983763 ]\n",
      " [0.48846254]\n",
      " [0.4928892 ]\n",
      " [0.49533808]\n",
      " [0.48586705]\n",
      " [0.4922794 ]\n",
      " [0.49203762]\n",
      " [0.4977969 ]\n",
      " [0.49033204]\n",
      " [0.49584946]\n",
      " [0.49275547]\n",
      " [0.49725142]\n",
      " [0.51684517]\n",
      " [0.5032636 ]\n",
      " [0.49342272]\n",
      " [0.49565023]\n",
      " [0.49372804]\n",
      " [0.50687474]\n",
      " [0.5005761 ]\n",
      " [0.49661192]\n",
      " [0.4999811 ]\n",
      " [0.49273446]\n",
      " [0.5050194 ]\n",
      " [0.4924851 ]\n",
      " [0.49604905]\n",
      " [0.49401045]\n",
      " [0.502818  ]\n",
      " [0.4959592 ]\n",
      " [0.4917011 ]\n",
      " [0.49071386]\n",
      " [0.4903041 ]\n",
      " [0.4692888 ]\n",
      " [0.49794486]\n",
      " [0.4881182 ]\n",
      " [0.4976501 ]\n",
      " [0.4961946 ]\n",
      " [0.4992023 ]\n",
      " [0.5003078 ]\n",
      " [0.49357167]\n",
      " [0.49124777]\n",
      " [0.498767  ]\n",
      " [0.5056143 ]\n",
      " [0.50046843]\n",
      " [0.49851945]\n",
      " [0.49777496]\n",
      " [0.49948898]\n",
      " [0.4942967 ]\n",
      " [0.48707667]\n",
      " [0.49243402]\n",
      " [0.48109624]\n",
      " [0.49959984]\n",
      " [0.49062636]\n",
      " [0.5004215 ]\n",
      " [0.49255013]\n",
      " [0.49795717]\n",
      " [0.5024601 ]\n",
      " [0.5043415 ]\n",
      " [0.4963004 ]\n",
      " [0.49211916]\n",
      " [0.48652074]\n",
      " [0.49041298]\n",
      " [0.49119323]\n",
      " [0.49067813]]\n",
      "0.7475051\n",
      "step 2\n",
      "[[[0.5563056  0.4617699  0.5292343  ... 0.48490804 0.5062252  0.4879065 ]\n",
      "  [0.5563056  0.4617699  0.5292343  ... 0.48490804 0.5062252  0.4879065 ]\n",
      "  [0.5563056  0.4617699  0.5292343  ... 0.48490804 0.5062252  0.4879065 ]\n",
      "  ...\n",
      "  [0.6640171  0.47261634 0.5185052  ... 0.37591156 0.54661596 0.45782351]\n",
      "  [0.6640171  0.47261634 0.5185052  ... 0.37591156 0.54661596 0.45782351]\n",
      "  [0.6640171  0.47261634 0.5185052  ... 0.37591156 0.54661596 0.45782351]]\n",
      "\n",
      " [[0.5181168  0.5096923  0.5158308  ... 0.48172438 0.45053598 0.5086525 ]\n",
      "  [0.5181168  0.5096923  0.5158308  ... 0.48172438 0.45053598 0.5086525 ]\n",
      "  [0.5181168  0.5096923  0.5158308  ... 0.48172438 0.45053598 0.5086525 ]\n",
      "  ...\n",
      "  [0.66405827 0.4729085  0.51850784 ... 0.37574333 0.54655814 0.4575585 ]\n",
      "  [0.66405827 0.4729085  0.51850784 ... 0.37574333 0.54655814 0.4575585 ]\n",
      "  [0.66405827 0.4729085  0.51850784 ... 0.37574333 0.54655814 0.4575585 ]]\n",
      "\n",
      " [[0.563533   0.47622037 0.5274757  ... 0.4747617  0.50649446 0.47214663]\n",
      "  [0.5355387  0.48183432 0.53250533 ... 0.48024577 0.49687585 0.4950574 ]\n",
      "  [0.5355387  0.48183432 0.53250533 ... 0.48024577 0.49687585 0.4950574 ]\n",
      "  ...\n",
      "  [0.6642267  0.4729469  0.5184121  ... 0.37616646 0.54661214 0.45730555]\n",
      "  [0.6642267  0.4729469  0.5184121  ... 0.37616646 0.54661214 0.45730555]\n",
      "  [0.6642267  0.4729469  0.5184121  ... 0.37616646 0.54661214 0.45730555]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.55304843 0.49283507 0.49948242 ... 0.48318583 0.5339839  0.49307948]\n",
      "  [0.55304843 0.49283507 0.49948242 ... 0.48318583 0.5339839  0.49307948]\n",
      "  [0.5222146  0.50017583 0.5125117  ... 0.49212497 0.51835346 0.5178569 ]\n",
      "  ...\n",
      "  [0.66446114 0.47294047 0.5183124  ... 0.3758342  0.5465014  0.4575907 ]\n",
      "  [0.66446114 0.47294047 0.5183124  ... 0.3758342  0.5465014  0.4575907 ]\n",
      "  [0.66446114 0.47294047 0.5183124  ... 0.3758342  0.5465014  0.4575907 ]]\n",
      "\n",
      " [[0.57062936 0.5204817  0.48743433 ... 0.46698412 0.5268667  0.5016679 ]\n",
      "  [0.57062936 0.5204817  0.48743433 ... 0.46698412 0.5268667  0.5016679 ]\n",
      "  [0.57062936 0.5204817  0.48743433 ... 0.46698412 0.5268667  0.5016679 ]\n",
      "  ...\n",
      "  [0.66379225 0.47293526 0.5189763  ... 0.37577736 0.54717934 0.4577034 ]\n",
      "  [0.66379225 0.47293526 0.5189763  ... 0.37577736 0.54717934 0.4577034 ]\n",
      "  [0.66379225 0.47293526 0.5189763  ... 0.37577736 0.54717934 0.4577034 ]]\n",
      "\n",
      " [[0.55758184 0.51306856 0.5953506  ... 0.49965107 0.5597426  0.5035182 ]\n",
      "  [0.55758184 0.51306856 0.5953506  ... 0.49965107 0.5597426  0.5035182 ]\n",
      "  [0.55758184 0.51306856 0.5953506  ... 0.49965107 0.5597426  0.5035182 ]\n",
      "  ...\n",
      "  [0.66487885 0.47285458 0.51866055 ... 0.375703   0.5466223  0.4571288 ]\n",
      "  [0.66487885 0.47285458 0.51866055 ... 0.375703   0.5466223  0.4571288 ]\n",
      "  [0.66487885 0.47285458 0.51866055 ... 0.375703   0.5466223  0.4571288 ]]]\n",
      "batch 0 completed! encoder loss: 11.445018768310547 discriminator loss: 0.7143111824989319 generator_loss: 0.7334092855453491\n",
      "10 batches completed\n",
      "getting data\n",
      "(100, 1536, 88)\n",
      "got data\n",
      "step 1\n",
      "[[0.4765714 ]\n",
      " [0.49319375]\n",
      " [0.4791383 ]\n",
      " [0.48450634]\n",
      " [0.48620227]\n",
      " [0.49125242]\n",
      " [0.4950603 ]\n",
      " [0.49700472]\n",
      " [0.49237695]\n",
      " [0.47915202]\n",
      " [0.5082337 ]\n",
      " [0.4880812 ]\n",
      " [0.5099158 ]\n",
      " [0.49605668]\n",
      " [0.50123984]\n",
      " [0.51130587]\n",
      " [0.49957642]\n",
      " [0.48999143]\n",
      " [0.49580264]\n",
      " [0.49095318]\n",
      " [0.4991045 ]\n",
      " [0.5059782 ]\n",
      " [0.49133992]\n",
      " [0.49291572]\n",
      " [0.48965153]\n",
      " [0.49480146]\n",
      " [0.5014018 ]\n",
      " [0.49556994]\n",
      " [0.49645206]\n",
      " [0.48956656]\n",
      " [0.47772327]\n",
      " [0.49167657]\n",
      " [0.51133025]\n",
      " [0.49978262]\n",
      " [0.50376713]\n",
      " [0.49938315]\n",
      " [0.4744907 ]\n",
      " [0.5017127 ]\n",
      " [0.5060158 ]\n",
      " [0.51033896]\n",
      " [0.4784174 ]\n",
      " [0.4934408 ]\n",
      " [0.5002902 ]\n",
      " [0.48853648]\n",
      " [0.48718378]\n",
      " [0.51414686]\n",
      " [0.4924532 ]\n",
      " [0.51842344]\n",
      " [0.49261647]\n",
      " [0.49551213]\n",
      " [0.5016696 ]\n",
      " [0.48191178]\n",
      " [0.5028889 ]\n",
      " [0.5099268 ]\n",
      " [0.48010606]\n",
      " [0.5045822 ]\n",
      " [0.4905652 ]\n",
      " [0.50044495]\n",
      " [0.48816112]\n",
      " [0.5004652 ]\n",
      " [0.49350798]\n",
      " [0.484242  ]\n",
      " [0.50547534]\n",
      " [0.5003639 ]\n",
      " [0.49920008]\n",
      " [0.5058709 ]\n",
      " [0.48057726]\n",
      " [0.49191493]\n",
      " [0.49754697]\n",
      " [0.49167636]\n",
      " [0.4948278 ]\n",
      " [0.5138213 ]\n",
      " [0.49782622]\n",
      " [0.4972435 ]\n",
      " [0.50185066]\n",
      " [0.50367486]\n",
      " [0.48208848]\n",
      " [0.49571815]\n",
      " [0.4982613 ]\n",
      " [0.49022004]\n",
      " [0.49749196]\n",
      " [0.50457513]\n",
      " [0.5041009 ]\n",
      " [0.49400637]\n",
      " [0.49419844]\n",
      " [0.5109945 ]\n",
      " [0.5119478 ]\n",
      " [0.49885294]\n",
      " [0.49894226]\n",
      " [0.49474013]\n",
      " [0.50061536]\n",
      " [0.46469152]\n",
      " [0.4874887 ]\n",
      " [0.5014097 ]\n",
      " [0.5000738 ]\n",
      " [0.46974596]\n",
      " [0.5025596 ]\n",
      " [0.49352312]\n",
      " [0.49792403]\n",
      " [0.5029249 ]]\n",
      "0.74767554\n",
      "step 2\n",
      "[[[0.53385675 0.48919344 0.55172825 ... 0.5388026  0.55823165 0.49895802]\n",
      "  [0.53385675 0.48919344 0.55172825 ... 0.5388026  0.55823165 0.49895802]\n",
      "  [0.53385675 0.48919344 0.55172825 ... 0.5388026  0.55823165 0.49895802]\n",
      "  ...\n",
      "  [0.6505982  0.4732473  0.50179553 ... 0.35767978 0.5342584  0.44782442]\n",
      "  [0.6505982  0.4732473  0.50179553 ... 0.35767978 0.5342584  0.44782442]\n",
      "  [0.6505982  0.4732473  0.50179553 ... 0.35767978 0.5342584  0.44782442]]\n",
      "\n",
      " [[0.5101091  0.51876277 0.5000549  ... 0.4636944  0.5029168  0.48466167]\n",
      "  [0.5101091  0.51876277 0.5000549  ... 0.4636944  0.5029168  0.48466167]\n",
      "  [0.5101091  0.51876277 0.5000549  ... 0.4636944  0.5029168  0.48466167]\n",
      "  ...\n",
      "  [0.6507703  0.47309744 0.5018964  ... 0.35744616 0.5343327  0.44751632]\n",
      "  [0.6507703  0.47309744 0.5018964  ... 0.35744616 0.5343327  0.44751632]\n",
      "  [0.6507703  0.47309744 0.5018964  ... 0.35744616 0.5343327  0.44751632]]\n",
      "\n",
      " [[0.5553448  0.508869   0.5090325  ... 0.48641443 0.5006585  0.47050983]\n",
      "  [0.5553448  0.508869   0.5090325  ... 0.48641443 0.5006585  0.47050983]\n",
      "  [0.5545538  0.5293317  0.5452118  ... 0.49302205 0.50718063 0.47684985]\n",
      "  ...\n",
      "  [0.650947   0.4730138  0.50187975 ... 0.35811198 0.5341884  0.44776735]\n",
      "  [0.650947   0.4730138  0.50187975 ... 0.35811198 0.5341884  0.44776735]\n",
      "  [0.650947   0.4730138  0.50187975 ... 0.35811198 0.5341884  0.44776735]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.51189303 0.50805545 0.51439786 ... 0.49049574 0.5144324  0.48910305]\n",
      "  [0.51189303 0.50805545 0.51439786 ... 0.49049574 0.5144324  0.48910305]\n",
      "  [0.51189303 0.50805545 0.51439786 ... 0.49049574 0.5144324  0.48910305]\n",
      "  ...\n",
      "  [0.6503785  0.47349855 0.5021624  ... 0.35750467 0.53434736 0.44776037]\n",
      "  [0.65037847 0.47349855 0.5021624  ... 0.35750467 0.53434736 0.44776037]\n",
      "  [0.65037847 0.47349855 0.5021624  ... 0.35750467 0.53434736 0.44776037]]\n",
      "\n",
      " [[0.5288324  0.48061782 0.49447787 ... 0.4793132  0.47070393 0.4837897 ]\n",
      "  [0.5288324  0.48061782 0.49447787 ... 0.4793132  0.47070393 0.4837897 ]\n",
      "  [0.5288324  0.48061782 0.49447787 ... 0.4793132  0.47070393 0.4837897 ]\n",
      "  ...\n",
      "  [0.65092707 0.47275957 0.502078   ... 0.35785782 0.5341758  0.44786346]\n",
      "  [0.65092707 0.47275957 0.502078   ... 0.35785782 0.5341758  0.44786346]\n",
      "  [0.65092707 0.47275957 0.502078   ... 0.35785782 0.5341758  0.44786346]]\n",
      "\n",
      " [[0.50488555 0.49748257 0.48515484 ... 0.46758693 0.51025075 0.5034247 ]\n",
      "  [0.50488555 0.49748257 0.48515484 ... 0.46758693 0.51025075 0.5034247 ]\n",
      "  [0.50488555 0.49748257 0.48515484 ... 0.46758693 0.51025075 0.5034247 ]\n",
      "  ...\n",
      "  [0.6510968  0.47298777 0.5016358  ... 0.35793656 0.5343432  0.4479655 ]\n",
      "  [0.6510968  0.47298777 0.5016358  ... 0.35793656 0.5343432  0.4479655 ]\n",
      "  [0.6510968  0.47298777 0.5016358  ... 0.35793656 0.5343432  0.4479655 ]]]\n",
      "batch 1 completed! encoder loss: 12.676565170288086 discriminator loss: 0.7149962186813354 generator_loss: 0.7275578379631042\n",
      "getting data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1536, 88)\n",
      "got data\n",
      "step 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-27fc47ef97d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtotal_fake_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_data_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0md_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_fake_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_discriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences_dis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_discriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences_dis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1173\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    num_batches = num_total_data // batch_size\n",
    "    dis_list = list(range(num_total_data))\n",
    "    gen_list = list(range(num_total_data))\n",
    "    random.shuffle(dis_list)\n",
    "    random.shuffle(gen_list)\n",
    "    for i in range(num_batches):\n",
    "        print(\"getting data\")\n",
    "        start_data_gen = next_batch(gen_list[i*batch_size:i*batch_size + batch_size], 1536)\n",
    "        sequences_dis = next_batch(dis_list[i*batch_size:i*batch_size + batch_size], 3072)\n",
    "        print(start_data_gen.shape)\n",
    "        print(\"got data\")\n",
    "        encoder_loss = encoder_decoder.train_on_batch([sequences_dis,start_data_gen], [sequences_dis, start_data_gen])\n",
    "        print(\"step 1\"),\n",
    "        total_fake_data = generator.predict(start_data_gen)\n",
    "        d_loss_fake = discriminator.train_on_batch(total_fake_data, tf.zeros(batch_size))\n",
    "        d_loss_real = real_discriminator.train_on_batch(sequences_dis, tf.ones(batch_size)*.9)\n",
    "        print(real_discriminator.predict(sequences_dis))\n",
    "        print(d_loss_real)\n",
    "        print(\"step 2\")\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        g_loss = combined.train_on_batch(start_data_gen, tf.ones(batch_size))\n",
    "        g_test = decoder_model.predict(generator.predict(start_data_gen))\n",
    "        print(g_test)\n",
    "        print(\"batch {} completed! encoder loss: {} discriminator loss: {} generator_loss: {}\".format(i, encoder_loss[0],d_loss,g_loss))\n",
    "        if i % 10 == 0:\n",
    "            print(\"10 batches completed\")\n",
    "            single_start_data = next_batch([random.randint(0,num_total_data)], 1536)\n",
    "            sample_new_data = generator.predict(single_start_data)\n",
    "            with open(\"./test_results/test1.pickle\", \"wb+\") as file:\n",
    "                pickle.dump(sample_new_data, file)\n",
    "                              \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
